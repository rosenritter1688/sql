{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://blog.csdn.net/LeiLiFengX/article/details/109922043\n",
    "## pandas 写入mysql数据库.to_sql方法详解"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "to_sql()方法参数解析：\n",
    "name:指定的是将输入接入数据库当做的哪个表\n",
    "\n",
    "con：与数据库链接的方式，推荐使用sqlalchemy的engine类型\n",
    "\n",
    "schema: 相应数据库的引擎，不设置则使用数据库的默认引擎，如mysql中的innodb引擎\n",
    "\n",
    "if_exists: 当数据库中已经存在数据表时对数据表的操作，有replace替换、append追加，fail则当表存在时提示ValueError。\n",
    "\n",
    "index：对DataFrame的index索引的处理，为True时索引也将作为数据写入数据表\n",
    "\n",
    "index_label:当上一个参数index为True时，设置写入数据表时index的列名称\n",
    "\n",
    "chunsize：设置整数，如20000，一次写入数据时的数据行数量，当数据量很大时，需要设置，否则会链接超时写入失败。\n",
    "\n",
    "dtype：写入数据表时，可以设置列的名称(The keys should be the column names and the values should be the SQLAlchemy types or strings for\n",
    "the sqlite3 legacy mode),需要设置时，类型需要和sqlalchemy的类型保持一致.当不设置时，to_sql生成表时会自动兼容最大的类型。\n",
    "```\n",
    "#### .to_sql()参数中除 name、con必填外，可选参数index推荐使用False，同时dtype推荐不使用。\n",
    "\n",
    "#### to_sql方法当数据表不存在时创建，存在时根据if_exists参数设置的replace，append，fail时分别对应替换、追加、失败处理。\n",
    "\n",
    "#### 数据库中对表的增删改，最好是在数据库层面处理，不应该由to_sql()方法设置，虽然这个方法本身可以在表不存在时增加表，但是不推荐。在数据库层面设计表，需要根据表的数据，不同的字段设计合理的存储类型，可以对表进行合理的设计和优化。to_sql()本身创建的表，浮点类型是double，整型bigint，字符类型默认兼容最大的text，虽然可以使用dtype参数设置类型，但我个人不推荐使用。还是建议在数据库中先创建合理的目标表，在根据to_sql()方法，将数据写入目标表中。\n",
    "\n",
    "\n",
    "#### 如果你觉得你电脑配置很强大的话，还可以在to_sql中添加此参数：\n",
    "```\n",
    "method=‘multi’\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#? sqlalchemy.create_engine()的两种方式： \n",
    "# data_engine = create_engine('mysql+mysqldb://root:19821205@127.0.0.1/sql_fr_ai?charset=utf8') \n",
    "data_engine = create_engine('mysql+mysqlconnector:// root:19821205@127.0.0.1/sql_fr_ai?charset=utf8') \n",
    "# user:passwd@127.0.0.1/database  --> 格式为 用户名:密码@服务器地址/数据库名\n",
    "\n",
    "#! sample holiday_master.csv has no header and no index\n",
    "holiday_data = pd.read_csv('D:/AI academic/教材とデータ/02.SQL/01.教材/DATA/holiday_master.csv',header=None,index_col=False, delimiter = ',')\n",
    "holiday_data.columns =[\"Date_YMD\", \"Public_Holiday\"]\n",
    "#holiday_data\n",
    "\n",
    "\n",
    "# pandas to_sql() function\n",
    "holiday_data.to_sql(\n",
    "    'holiday_master_hsuan',\n",
    "    con = data_engine,\n",
    "    if_exists='replace',   #! 有replace替换、append追加，fail则当表存在时提示ValueError。\n",
    "    index=False,\n",
    "    method=\"multi\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas高效率插入数据(to_sql进阶用法)\n",
    "#### 当前只有sqlserver支持此用法\n",
    "```\n",
    "connection_string = \"xxxxxxxxx\"\n",
    "engine = create_engine(\n",
    "                                        connection_string,\n",
    "                                        fast_executemany=True)\n",
    "```\n",
    "\n",
    "#### 如果你觉得你电脑配置很强大的话，还可以在to_sql中添加此参数：\n",
    "```\n",
    "method=‘multi’\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e748360335f2bf9c5c12ffe143cd93812385ddcb6c3d461a4ee3fa3233acffe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
